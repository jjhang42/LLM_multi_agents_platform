version: "3.8"

services:
  frontend:
    build:
      context: ./
      dockerfile: docker/Dockerfile.frontend
    volumes:
      - ./frontend:/app
    ports:
      - "${FRONTEND_PORT}:3000"
    env_file:
      - .env
    networks:
      - llm-net

  api_gateway:
    build:
      context: .
      dockerfile: docker/Dockerfile.api_gateway
    container_name: aiagent-api_gateway
    ports:
      - "4000:8000"
    depends_on:
      - orchestrator
    networks:
      - llm-net

  orchestrator:
    build:
      context: .
      dockerfile: docker/Dockerfile.orchestrator
    volumes:
      - ./apps/orchestrator:/app/orchestrator
    ports:
      - "${ORCHESTRATOR_PORT:-8000}:8000"
    env_file:
      - .env
    networks:
      - llm-net

  broker:
    build:
      context: .
      dockerfile: docker/Dockerfile.broker
    volumes:
      - ./apps/broker:/app/broker
    ports:
      - "${BROKER_PORT:-8001}:8000"
    depends_on:
      - orchestrator
    env_file:
      - .env
    networks:
      - llm-net

  agent_core:
    build:
      context: .
      dockerfile: docker/Dockerfile.agent_core
    volumes:
      - ./apps/agent_core:/app/agent_core
    ports:
      - "${AGENT_CORE_PORT:-8010}:8000"
    depends_on:
      - broker
    env_file:
      - .env
    networks:
      - llm-net

  agent_model:
    build:
      context: .
      dockerfile: docker/Dockerfile.agent_model
    volumes:
      - ./apps/agent_model:/app/agent_model
    ports:
      - "${AGENT_MODEL_PORT:-8011}:8000"
    depends_on:
      - agent_core
    env_file:
      - .env
    networks:
      - llm-net

networks:
  llm-net:
    driver: bridge
