import os
import httpx
import uuid
import json
from typing import List, Dict, Any
from string import Template

from core.adapters.planner.llm_planner_base import LLMPlannerBase
from core.system.formats.a2a_part import Part
from core.system.utils.chat_task_builder import make_chat_response_task
from core.prompts.loader import load_prompt


class ClaudePlannerAdapter(LLMPlannerBase):
    def __init__(self):
        self.api_key = os.getenv("ORCHESTRATOR_CLAUDE_API_KEY", os.getenv("CLAUDE_API_KEY"))
        self.api_base = os.getenv("ORCHESTRATOR_CLAUDE_API_BASE", "https://api.anthropic.com/v1")
        self.model = os.getenv("ORCHESTRATOR_CLAUDE_MODEL", "claude-3-opus-20240229")

        self.prompt_parse_task = load_prompt("planner_parse_task.txt")
        self.prompt_generate_nl = load_prompt("planner_generate_natural_language.txt")

        if not self.api_key:
            raise ValueError("âŒ í™˜ê²½ ë³€ìˆ˜ 'CLAUDE_API_KEY' ë˜ëŠ” 'ORCHESTRATOR_CLAUDE_API_KEY'ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    async def _call_llm_with_parts(self, context: Dict[str, Any]) -> str:
        parts = context.get("parts", [])
        agent_cards = context.get("agent_cards", [])
        prior_tasks = context.get("prior_tasks", [])

        user_text = next((p.text for p in parts if p.type == "text"), "")
        agent_skill_ids = [card.get("id", "unknown") for card in agent_cards]
        prior_task_ids = [t.get("id", "task") for t in prior_tasks]

        prompt = f"""
{self.prompt_parse_task.strip()}

[ì‚¬ìš©ì ìš”ì²­]
{user_text}

[ì‚¬ìš© ê°€ëŠ¥ ì—ì´ì „íŠ¸ ìŠ¤í‚¬ ID ëª©ë¡]
{agent_skill_ids}

[ì´ì „ ì‘ì—…ë“¤]
{prior_task_ids}
        """.strip()

        return await self._send_claude_prompt(prompt)

    async def _chat_response(self, parts: List[Part]):
        user_text = next((p.text for p in parts if p.type == "text"), "")
        prompt = f"ë‹¤ìŒ ì‚¬ìš©ì ë©”ì‹œì§€ì— ì§§ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:\n\n\"{user_text}\""
        response = await self._send_claude_prompt(prompt)
        return make_chat_response_task(response)

    async def generate_natural_language(self, task: dict) -> str:
        task_text = str(task)
        prompt = Template(self.prompt_generate_nl).substitute(task_text=task_text)
        return await self._send_claude_prompt(prompt)

    async def _send_claude_prompt(self, prompt: str) -> str:
        headers = {
            "x-api-key": self.api_key,
            "anthropic-version": "2023-06-01",
            "Content-Type": "application/json"
        }
        payload = {
            "model": self.model,
            "max_tokens": 2048,
            "messages": [
                {"role": "user", "content": prompt}
            ]
        }

        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(f"{self.api_base}/messages", headers=headers, json=payload)
            response.raise_for_status()
            data = response.json()

        # ë””ë²„ê¹…ìš© ì‘ë‹µ ì €ì¥ (ì„ íƒì )
        if os.getenv("DEBUG_SAVE_LLM_RESPONSE", "false").lower() == "true":
            path = f"/tmp/claude_response_{uuid.uuid4().hex[:8]}.json"
            with open(path, "w") as f:
                json.dump(data, f, indent=2)
            print(f"ğŸ“ Claude ì‘ë‹µ ì €ì¥ë¨: {path}")

        try:
            return data["content"][0]["text"]
        except (KeyError, IndexError) as e:
            raise RuntimeError(f"[ClaudePlanner] ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}\nì „ì²´ ì‘ë‹µ: {data}")
