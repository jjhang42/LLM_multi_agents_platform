from abc import ABC, abstractmethod
from typing import Dict, Tuple, List
from core.system.metadata.task_graph import TaskGraph
from core.system.parser.task_assembler import assemble_tasks_with_graph
from core.system.utils.llm_response_parser import llm_response_parser
from core.system.formats.a2a import Task
from core.system.formats.a2a_part import Part
import traceback


class LLMPlannerBase(ABC):
    async def parse(self, parts: List[Part]) -> Tuple[Dict[str, Task], TaskGraph]:
        """
        ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë©€í‹°ëª¨ë‹¬ íŒŒíŠ¸ ë°°ì—´ë¡œ ë°›ì•„ LLM í˜¸ì¶œ â†’ A2A Task + DAG ê·¸ë˜í”„ ìƒì„±
        - DAG ìœ íš¨ì„± ê²€ì‚¬ í¬í•¨
        - ì‹¤íŒ¨ ì‹œ 1íšŒ ì¬ì‹œë„
        """
        user_input = next((p.text for p in parts if getattr(p, "type", None) == "text"), "")

        for attempt in range(2):  # ìµœëŒ€ 2íšŒ ì‹œë„
            try:
                raw_response = await self._call_llm_with_parts(parts)

                parsed_tasks = self._parse_response(raw_response, user_input=user_input)

                tasks, graph = assemble_tasks_with_graph(parsed_tasks)

                if graph.has_cycle():
                    print("âŒ Invalid DAG: Cycle detected")
                    if attempt == 0:
                        print("ğŸ” Retrying...")
                        continue
                    else:
                        raise RuntimeError("DAG Cycle Error: LLM response is repetitive and invalid.")
                return tasks, graph

            except Exception as e:
                print(f"[Planner] Error occurred (attempt {attempt + 1}):", e)
                traceback.print_exc()
                if attempt == 1:
                    raise RuntimeError("LLM parsing or validation failed")

    @abstractmethod
    async def _call_llm_with_parts(self, parts: List[Part]) -> str:
        """
        parts ë°°ì—´ì„ LLM-friendly prompt í˜•ì‹ìœ¼ë¡œ ì§ë ¬í™” í›„ LLMì— ìš”ì²­.
        ì‹¤ì œ ëª¨ë¸ API í˜¸ì¶œì€ í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„í•©ë‹ˆë‹¤.
        """
        pass

    def _parse_response(self, text: str, user_input: str = "") -> List[Task]:
        """
        LLMì˜ JSON ì‘ë‹µ ë¬¸ìì—´ì„ Task[]ë¡œ íŒŒì‹±.
        - ìƒíƒœ ìë™ ë³´ì™„
        - message í•„ë“œ ì¶”ì •
        - timestamp ë“± ì‹œìŠ¤í…œ ì •ë³´ ì¶”ê°€
        """
        return llm_response_parser(text, Task, user_input=user_input)

    @abstractmethod
    async def generate_natural_language(self, task: dict) -> str:
        """
        Task ê°ì²´ë¥¼ ìì—°ì–´ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜ (ìš”ì•½ ë“±)
        """
        pass
